# PROJECT TITLE : Instance-Segmentation-using-Mask-RCNN
A short description of the motivation behind the creation and maintenance of the project. This should explain why the project exists.
# AIM OF THE PROJECT 
The goal of "instance segmentation", a unique sort of image segmentation, is to locate and identify each unique instance of something that occurs in a photograph. I have created custom dataset with 2 classes Cars and Sign Board which are collected around a Private University. 
We are segmentating the image with single class instead of using mutiple classes in the same image
As a part of our Final Project for DEEP lEARNING. we have choosen "Instance Segmentation Topic" built using Mask RCNN architecture. 
In the First update for our project. We have annotated our images and reduced the image size for Data Processing. In the first update, we have used Bounding Boxes for each image but later we have used polygon shape for annotating the images.
 Annotation Tool : LABELME 
# UPDATE-02 IMPLEMENTING PRETRAINED MODEL :
We generate the masked images from the original dataset 
# SAMPLE MASKED IMAGES: 
![image](https://github.com/Likhitachandana/Instance-Segmentation-using-Mask-RCNN/assets/52712285/0fe3d9b1-e266-4f86-98c5-2dbcacbf8eb7)
# PRE-TRAINED MODEL USED:
The get_model_instance_segmentation function, which uses the Mask R-CNN architecture to construct an instance segmentation model, is defined in the code. A computer vision job called instance segmentation entails locating and categorizing each instance of an object present in a picture.
# UPDATE-03 MINI NETWORK with Transfer Learning Implementation :
The model uses transfer learning by initializing the ResNet backbone with weights pre-trained on the ImageNet dataset. This allows the model to leverage the features learned by the pre-trained network and fine-tune them for the specific task of object detection.
# Configuration of each layer:
ResNet Backbone: The ResNet backbone network consists of several residual blocks, each containing multiple convolutional layers with batch normalization and ReLU activation. The specific configuration of the ResNet architecture used in this model is ResNet-18.
Feature Pyramid Network (FPN): The FPN takes features from the ResNet backbone and generates a set of feature maps at different scales. It does this by applying a series of convolutional layers to the ResNet features and upsampling them to create a feature pyramid.
Region Proposal Network (RPN): The RPN takes the feature maps generated by the FPN and generates region proposals, which are areas of the image that are likely to contain objects. It does this by applying a set of convolutional layers and anchor boxes to the feature maps.
ROI Align Pooling: The ROI Align Pooling layer takes the region proposals generated by the RPN and extracts features from the feature maps at the corresponding locations. It does this by aligning the feature maps with the region proposals using bilinear interpolation.
Box and Mask Heads: The box head takes the ROI-pooled features and passes them through a series of fully connected layers to predict the bounding box coordinates and class probabilities. The mask head takes the ROI-pooled features and passes them through a series of convolutional layers to predict a binary mask for each class.
Overall, this model uses a combination of convolutional layers, pooling layers, and fully connected layers to perform object detection on input images. It leverages transfer learning by using a pre-trained ResNet backbone and fine-tuning it for the specific task for segmentation task. 
# HYPER PARAMETERS USED: 
The learning rate (lr), which controls how much the optimizer modifies the parameters in response to calculated gradients, is set to 0.00001. 
The optimizer moves in the same direction as earlier stages and speeds up convergence when the momentum parameter (momentum) is set to 0.9. 
By penalizing big weights, the weight decay (weight_decay) parameter, a type of L2 regularization that aids in preventing overfitting, is set to 0.0005.
After iterating through for 50 epochs. The graph below shows the loss function value.
![image](https://github.com/Likhitachandana/Instance-Segmentation-using-Mask-RCNN/assets/52712285/33d41476-ee2f-4374-a990-bcfce310d5de)
